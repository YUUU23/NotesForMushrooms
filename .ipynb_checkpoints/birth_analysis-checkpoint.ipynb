{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2029de1b-de64-4c05-a385-b34e0059f17a",
   "metadata": {},
   "source": [
    "# Birth analysis from split annotations \n",
    "- Given a dataset of number of births\n",
    "by name/year, computes fraction of\n",
    "names starting with “Lesl” grouped\n",
    "by gender and year-of-birth\n",
    "- Code: https://github.com/weld-project/split-annotations/blob/master/python/benchmarks/birth_analysis/birth_analysis.py\n",
    "- Data: https://github.com/weld-project/split-annotations/blame/master/python/benchmarks/datasets/birth_analysis/babynames.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c1c6b9-50fb-4792-ac7c-fb794dabf680",
   "metadata": {},
   "source": [
    "## Notes: \n",
    "- This is the original python script, it is not really in a notebook top to bottom way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d38f41f-d949-4d6a-b73c-abc418e0e3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92a115d-6d32-448e-aa6f-7bcac1df8596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ./data/babynames.txt\n",
      "done.ng data...\n",
      "Size of names: 1792091\n",
      "GroupBy: 0.0035479068756103516\n",
      "Apply: 0.4545860290527344\n",
      "Elements in top1000: 267877\n",
      "Analysis: 0.04907989501953125\n",
      "Total time: 0.5072929859161377\n",
      "304919459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/f47m_fzj7cb6grp4vc8q8h880000gn/T/ipykernel_27526/4095733814.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  top1000 = grouped.apply(get_top1000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "\n",
    "def get_top1000(group):\n",
    "    return group.sort_values(by='births', ascending=False)[0:1000]\n",
    "\n",
    "def analyze(top1000):\n",
    "    start1 = time.time()\n",
    "    all_names = pd.Series(top1000.name.unique())\n",
    "    lesley_like = all_names[all_names.str.lower().str.contains('lesl')]\n",
    "    filtered = top1000[top1000.name.isin(lesley_like)]\n",
    "    table = filtered.pivot_table('births', index='year',\n",
    "                                 columns='sex', aggfunc='sum')\n",
    "\n",
    "    table = table.div(table.sum(1), axis=0)\n",
    "    end1 = time.time()\n",
    "    print(\"Analysis:\", end1 - start1)\n",
    "    return table\n",
    "\n",
    "def run(filename):\n",
    "    years = range(1880, 2011)\n",
    "    pieces = []\n",
    "    columns = ['year', 'sex', 'name', 'births']\n",
    "\n",
    "    sys.stdout.write(\"Reading data...\")\n",
    "    sys.stdout.flush()\n",
    "    names = pd.read_csv(filename, names=columns)\n",
    "    print(\"done.\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    print(\"Size of names:\", len(names))\n",
    "\n",
    "    e2e_start = time.time()\n",
    "\n",
    "    # Time preprocessing step\n",
    "    start0 = time.time()\n",
    "    grouped = names.groupby(['year', 'sex'])\n",
    "    end0 = time.time()\n",
    "    print(\"GroupBy:\", end0 - start0)\n",
    "    start0 = end0\n",
    "\n",
    "    top1000 = grouped.apply(get_top1000)\n",
    "    top1000.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    end0 = time.time()\n",
    "    print(\"Apply:\", end0-start0)\n",
    "    print(\"Elements in top1000:\", len(top1000))\n",
    "\n",
    "    result = analyze(top1000)\n",
    "\n",
    "    e2e_end = time.time()\n",
    "    print(\"Total time:\", e2e_end - e2e_start)\n",
    "\n",
    "    print(top1000['births'].sum())\n",
    "\n",
    "def main(filename: str):\n",
    "    print(\"File:\", filename)\n",
    "    mi = run(filename)\n",
    "\n",
    "\n",
    "main('./data/babynames.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7490f0f8-a49d-4b67-8c74-0489b15c9c33",
   "metadata": {},
   "source": [
    "## Notes: \n",
    "- Refactored into a more notebook style \n",
    "- There are some groupby -> sort -> filter (by name and uniqueness (more like merge?)) -> sum, which may be effective organize sort after groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "466db81d-dc0c-4ecb-a834-48bca52657de",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(1880, 2011)\n",
    "pieces = []\n",
    "columns = ['year', 'sex', 'name', 'births']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c243140f-fe19-4de5-86bd-012ebb86eda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ./data/babynames.txt\n",
      "Reading data...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "filename = './data/babynames.txt'\n",
    "print(\"File:\", filename)\n",
    "\n",
    "print(\"Reading data...\")\n",
    "names = pd.read_csv(filename, names=columns)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f033324b-6bf2-430f-ae38-f4a79529cbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupBy: 0.002891063690185547\n"
     ]
    }
   ],
   "source": [
    "e2e_start = time.time()\n",
    "start0 = time.time()\n",
    "grouped = names.groupby(['year', 'sex']) #  Groups the data by year and sex \n",
    "end0 = time.time()\n",
    "print(\"GroupBy:\", end0 - start0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1251c373-c187-4f1f-9fe7-d10eaf0aaeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply: 2.201852798461914\n",
      "Elements in top1000: 267877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/f47m_fzj7cb6grp4vc8q8h880000gn/T/ipykernel_36687/1309563262.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  top1000 = grouped.apply(lambda group: group.sort_values(by='births', ascending=False)[0:1000])\n"
     ]
    }
   ],
   "source": [
    "start0 = end0\n",
    "\n",
    "top1000 = grouped.apply(lambda group: group.sort_values(by='births', ascending=False)[0:1000])\n",
    "top1000.reset_index(inplace=True, drop=True)\n",
    "\n",
    "end0 = time.time()\n",
    "print(\"Apply:\", end0-start0)\n",
    "print(\"Elements in top1000:\", len(top1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e98ca3c5-2109-458b-b531-f36020a95bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis: 0.05785799026489258\n"
     ]
    }
   ],
   "source": [
    "start1 = time.time()\n",
    "all_names = pd.Series(top1000.name.unique()) # find all unique names \n",
    "lesley_like = all_names[all_names.str.lower().str.contains('lesl')]\n",
    "filtered = top1000[top1000.name.isin(lesley_like)] # filter \n",
    "table = filtered.pivot_table('births', index='year',\n",
    "                             columns='sex', aggfunc='sum') # births summed by year and sex\n",
    "\n",
    "table = table.div(table.sum(1), axis=0) # Normalize by dividing each row / total_births\n",
    "end1 = time.time()\n",
    "result = table\n",
    "print(\"Analysis:\", end1 - start1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f73a7d2-7625-447d-9955-72ecc97b5b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 5.948984146118164\n",
      "304919459\n"
     ]
    }
   ],
   "source": [
    "e2e_end = time.time()\n",
    "print(\"Total time:\", e2e_end - e2e_start)\n",
    "\n",
    "print(top1000['births'].sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
